---
title: "User Memory"
description: "Add memories to Cortex that can be used by your agents for learning about your users. This API allows you to ingest memories in various formats including text, markdown, and user-assistant pairs."
openapi: "POST /memories/add_memory"
---

### Sample Requests

<Tabs>
  <Tab title="API Request">
    ```bash expandable
    # Simple text memory (no inference)
    curl --request POST \
      --url https://api.usecortex.ai/memories/add_memory \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "memories": [
        {
          "text": "Company policy document v2.0 - All employees must...",
          "infer": false,
          "title": "Company Policy"
        }
      ],
      "tenant_id": "tenant-01",
      "sub_tenant_id": ""
    }'
    
    # Text with inference enabled
    curl --request POST \
      --url https://api.usecortex.ai/memories/add_memory \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "memories": [
        {
          "text": "User wakes up early and enjoys jogging before work",
          "infer": true,
          "user_name": "John",
          "custom_instructions": "Extract user preferences and habits"
        }
      ],
      "tenant_id": "tenant-01"
    }'
    
    # Markdown content
    curl --request POST \
      --url https://api.usecortex.ai/memories/add_memory \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "memories": [
        {
          "text": "# Meeting Notes\n\n## Attendees\n- John\n- Jane\n\n## Action Items\n1. Review Q3 budget\n2. Prepare presentation",
          "is_markdown": true,
          "infer": false,
          "title": "Q3 Planning Meeting"
        }
      ],
      "tenant_id": "tenant-01"
    }'
    
    # User-assistant conversation pairs
    curl --request POST \
      --url https://api.usecortex.ai/memories/add_memory \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "memories": [
        {
          "user_assistant_pairs": [
            {"user": "What is my favorite color?", "assistant": "Based on our previous conversations, you prefer blue."},
            {"user": "Remember that I like dark mode", "assistant": "Noted! I will remember that you prefer dark mode interfaces."}
          ],
          "infer": true,
          "user_name": "John"
        }
      ],
      "tenant_id": "tenant-01"
    }'
    
    # Batch upload - multiple items with mixed settings
    curl --request POST \
      --url https://api.usecortex.ai/memories/add_memory \
      --header 'Authorization: Bearer <token>' \
      --header 'Content-Type: application/json' \
      --data '{
      "memories": [
        {
          "text": "User prefers detailed explanations",
          "infer": true,
          "user_name": "John"
        },
        {
          "text": "Company policy document - version 2.0",
          "infer": false,
          "title": "Policy Doc"
        },
        {
          "user_assistant_pairs": [
            {"user": "What are my settings?", "assistant": "You have dark mode enabled."}
          ],
          "infer": true,
          "user_name": "John"
        }
      ],
      "tenant_id": "tenant-01"
    }'
    ```
  </Tab>
  <Tab title="TypeScript">
    ```ts expandable
    // Simple text memory
    const result = await client.memories.addMemory({
      memories: [
        {
          text: "User prefers detailed explanations and dark mode",
          infer: true,
          user_name: "John"
        }
      ],
      tenant_id: "tenant-01",
      sub_tenant_id: "",
      upsert: true
    });
    
    // Markdown content
    const markdownResult = await client.memories.addMemory({
      memories: [
        {
          text: "# Meeting Notes\n\n## Key Points\n- Budget approved\n- Launch date: Q2",
          is_markdown: true,
          infer: false,
          title: "Meeting Notes"
        }
      ],
      tenant_id: "tenant-01",
      sub_tenant_id: "",
      upsert: true
    });
    
    // User-assistant pairs with inference
    const conversationResult = await client.memories.addMemory({
      memories: [
        {
          user_assistant_pairs: [
            { user: "What are my preferences?", assistant: "You prefer dark mode and detailed explanations." },
            { user: "How do I like my reports?", assistant: "You prefer weekly summary reports with charts." }
          ],
          infer: true,
          user_name: "John",
          custom_instructions: "Extract user preferences"
        }
      ],
      tenant_id: "tenant-01",
      sub_tenant_id: "",
      upsert: true
    });
    ```
  </Tab>
  <Tab title="Python (Sync)">
    ```python expandable
    from cortex import CortexClient
    
    client = CortexClient(api_key="your_api_key")
    
    # Simple text memory
    result = client.memories.add_memory(
        memories=[
            {
                "text": "User prefers detailed explanations and dark mode",
                "infer": True,
                "user_name": "John"
            }
        ],
        tenant_id="tenant-01",
        sub_tenant_id="",
        upsert=True
    )
    
    # Markdown content
    markdown_result = client.memories.add_memory(
        memories=[
            {
                "text": "# Meeting Notes\n\n## Key Points\n- Budget approved",
                "is_markdown": True,
                "infer": False,
                "title": "Meeting Notes"
            }
        ],
        tenant_id="tenant-01",
        sub_tenant_id="",
        upsert=True
    )
    
    # User-assistant pairs with inference
    conversation_result = client.memories.add_memory(
        memories=[
            {
                "user_assistant_pairs": [
                    {"user": "What are my preferences?", "assistant": "You prefer dark mode."},
                    {"user": "How do I like reports?", "assistant": "Weekly summaries with charts."}
                ],
                "infer": True,
                "user_name": "John",
                "custom_instructions": "Extract user preferences"
            }
        ],
        tenant_id="tenant-01",
        sub_tenant_id="",
        upsert=True
    )
    ```
  </Tab>
</Tabs>

## Content Types

The API supports three types of content input:

### Text

```json
{
  "text": "Your text content here",
  "infer": false
}
```

### Markdown

```json
{
  "text": "# Title\n\n## Section\nContent here...",
  "is_markdown": true,
  "infer": false
}
```

### User-Assistant Pairs

```json
{
  "user_assistant_pairs": [
    {"user": "Question", "assistant": "Answer"}
  ],
  "infer": true
}
```

## Key Parameters

### `infer` (boolean)

Controls whether Cortex extracts insights, likes, dislikes, preferences, and outcomes from the content. If it nothing is specified, default behaviour is `true`

| Value   | Behavior                                                              |
| ------- | --------------------------------------------------------------------- |
| `false` | Content is ingested as-is (faster processing)                         |
| `true`  | Content is analyzed to extract information, preferences, and insights |

<Info>
  **`When to use infer=true:`**

  - Storing user conversations to extract preferences
  - Processing feedback or reviews
  - Extracting insights from unstructured text

  **`When to use infer=false:`**

  - Uploading factual statements
  - Storing deterministic data that doesn't need interpretation
</Info>

### `Upsert` parameter (optional)

For any form of memories, the identifier is `id`. When that identifier already exists, `upsert` (boolean, default `true`) controls the behavior:

| Value   | Behavior                   |
| ------- | -------------------------- |
| `true`  | Replace existing (default) |
| `false` | Fail; do not overwrite     |

Overwriting permanently removes and replaces existing memory for that identifier.

### `id` (optional)

Provide your own unique identifier, or let Cortex auto-generate one.

### `expiry_time` (optional)

Time-to-live in seconds. Memories will be automatically forgotten after this duration.

## Memory Item Fields

Each item in the `memories` array can have the following fields:

| Field                  | Type    | Required | Description                                  |
| ---------------------- | ------- | -------- | -------------------------------------------- |
| `text`                 | string  | \*       | Raw text or markdown content                 |
| `user_assistant_pairs` | array   | \*       | Array of conversation pairs                  |
| `is_markdown`          | boolean | No       | Whether text is markdown formatted           |
| `infer`                | boolean | No       | Enable inference processing (default: false) |
| `custom_instructions`  | string  | No       | Guide inference processing                   |
| `user_name`            | string  | No       | User's name for personalization              |
| `id`                   | string  | No       | Custom unique identifier                     |
| `title`                | string  | No       | Display title for the memory                 |
| `expiry_time`          | integer | No       | TTL in seconds                               |
| `tenant_metadata`      | string  | No       | JSON string of tenant-level metadata         |
| `document_metadata`    | string  | No       | JSON string of document-level metadata       |

## Response Format

```json
{
  "success": true,
  "message": "Memories queued for ingestion successfully",
  "results": [
    {
      "id": "abc123-def456",
      "title": "My Document",
      "status": "queued",
      "infer": false,
      "error": null
    }
  ],
  "success_count": 1,
  "failed_count": 0
}
```

## Processing Status

```bash
# Example: check status via ingestion verify_processing (when using id from ingestion flows)
curl -X POST \
  'https://api.usecortex.ai/ingestion/verify_processing?id=<id>&tenant_id=<tenant_id>' \
  -H 'Authorization: Bearer <token>'
```

### Status Values

| Status           | Description                             |
| ---------------- | --------------------------------------- |
| `queued`         | Content is waiting to be processed      |
| `processing`     | Content is being chunked and embedded   |
| `graph_creation` | Knowledge graph is being built          |
| `completed`      | Content is fully indexed and searchable |
| `errored`        | Processing failed (check error_code)    |

<Note>
  **Batch Uploads**: You can include multiple items in a single request for efficient bulk ingestion. Each item can have different `infer` settings.

  **Processing Time**:

  - `infer=false`: Typically 1-3 minutes. We update all nodes in your graph with new information
  - `infer=true`: May take slightly longer due to LLM inference processing
</Note>

## Migration from Previous APIs

This endpoint replaces and unifies:

- `/memories/add_memories` (deprecated)
- `/ingestion/upload_content` (deprecated)

### Key Changes

| Old API                   | New API                       |
| ------------------------- | ----------------------------- |
| `raw_text`                | `text`                        |
| `content` in body wrapper | `memories` array at top level |
| Separate endpoints        | Single unified endpoint       |