---
openapi: "POST /search/hybrid_search"
title: "Full Recall"
description: "Fetch personalized context that your agent needs to perform an action from its store"
---

### Examples

<Tabs>
  <Tab title="API Request">
    ```bash
    curl -X 'POST' \
    'https://api.usecortex.ai/recall/full_recall' \
    -H 'accept: application/json' \
    -H 'Content-Type: application/json' \
    -d '{
    "tenant_id": "string",
    "sub_tenant_id": "string",
    "query": "string",
    "mode": "fast",
    "max_results": 10,
    "extra_context": "string",
    }'
    ```
  </Tab>
  <Tab title="TypeScript">
    ```ts
    const results = await client.recall.full_recall({
      query: "Which mode does user prefer",
      tenantId: "tenant_1234",
      subTenantId: "sub_tenant_4567",
      alpha: 0.8,
      recencyBias: 0
    });
    ```
  </Tab>
  <Tab title="Python (Sync)">
    ```python
    # Async usage is similar, just use async_client and await
    results = client.recall.full_recall(
        query="Which mode does user prefer",
        tenant_id="tenant_1234",
        sub_tenant_id="sub_tenant_4567",
        alpha=0.8,
        recency_bias=0
    )
    ```
  </Tab>
</Tabs>

<Info>
  **Default Sub-Tenant Behavior**: If you don't specify a `sub_tenant_id`, the search will be performed within the default sub-tenant created when your tenant was set up. This searches across organization-wide documents.
</Info>

## How does recall happen?

When an agent queries Cortex, recall executes as a multi-stage, context-aware pipeline rather than a single vector lookup. The system first scopes the candidate set using deterministic signals (tenant, user, agent, task, and metadata constraints), then traverses the memory graph to surface relevant entities, relationships, and prior outcomes. On this scoped set, Cortex runs hybrid retrieval (semantic, lexical, and structured) and ranks results using a composite scoring function over recency, relevance, frequency, behavioral feedback, and semantic similarity. Instead of optimizing for “what is most similar?”, Cortex optimizes for “what context will maximize task success for this agent right now”, continuously adapting rankings as the system learns from usage.

## Optional Parameters

### Alpha

Controls the balance between semantic and keyword search:

- `0.0` - Pure keyword search focus
  - Best for: Exact term matching, technical specifications
  - Use when: You need precise keyword matches
- `1.0` - Pure semantic search focus
  - Best for: Conceptual queries, finding related content
  - Use when: You want to discover related concepts
- `0.8` - Balanced approach (default, recommended)
  - Best for: Most general use cases
  - Provides optimal balance of precision and recall
- **`"auto"`** - Intelligent auto-selection
  - Cortex analyzes your query and chooses the optimal alpha
  - Best for: When you're unsure which approach to use

### Recency Bias

Controls how much recent content is prioritized:

- **`0.1-0.5`** - Light to moderate recency preference
- `0.6` - Default behaviour to give more weightage to recent context
- **`0.6-1.0`** - Strong recency preference

### Max Results

Controls the number of results returned:

- **Range**: 1-1001
- **Default**: 10
- **Recommendation**: Start with 10-20 for most use cases

## Graph Context

Results are automatically enriched with knowledge graph context, providing entity relationships extracted from your content.

**What's included in responses:**

- **`extra_context.relations`** — Entities and relationships found within each chunk
- **`extra_graph_context`** — Additional entity relationships extracted from your query

This helps your AI understand not just _what_ is mentioned, but _how_ things relate—like knowing that "Sarah Chen" leads "Project Phoenix" which depends on the "Authentication Service".