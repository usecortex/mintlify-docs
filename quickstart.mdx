---
title: "Quickstart"
description: "Start building amazing LLM experiences in under 5 minutes"
---

> Base URL: `https://api.usecortex.ai`
>
> Contact us to get your API key at [founders@usecortex.ai](mailto:founders@usecortex.ai)

All endpoints require an API key sent as a Bearer token in the `Authorization` header.

```mdx
Authorization: Bearer <your_api_key>
```


## Quick Start

### Prerequisites

- Node.js / Python (or any backend language)
- Basic knowledge of HTTP requests
- An API key from [Cortex](https://usecortex.ai/) (`Authorization: Bearer <your_api_key>`)
- A document or webpage you want your AI to read

### **Step 0: Create a tenant (if needed)**

Create a tenant space for your data:

```mdx
POST /tenants/create
```

```mdx
curl -X POST 'https://api.usecortex.ai/tenants/create' \
  -H "Authorization: Bearer <your_api_key>" \
  -H "Content-Type: application/json" \
  -d '{"tenant_id": "your_tenant_id"}'
```

### **Step 1: Upload Your Knowledge Source**

You can upload documents (PDF, DOCX, etc.) or use the memories API for text/markdown.

#### Option A: Upload a document

```mdx
POST /ingestion/upload-document
```


**Form Data:**

- `file`: your document
- `tenant_id`: your unique tenant ID

```mdx
curl -X POST 'https://api.usecortex.ai/ingestion/upload-document' \
  -H "Authorization: Bearer <your_api_key>" \
  -F "file=@/path/to/your/document.pdf" \
  -F "tenant_id=your_tenant_id"
```

#### Option B: Add text or markdown via Memories API

Use [Add Memory](/api-reference/endpoint/add-memories) or [Add Knowledge Memories](/api-reference/endpoint/add-knowledge-memories) for text, markdown, or structured content.

### **Step 2 (Optional): Verify Processing**

Check if the document is fully indexed:

```mdx
POST /ingestion/verify-processing?file_id=YOUR_FILE_ID&tenant_id=your_tenant_id
```


Returns success once the document is ready for querying.

### **Step 3: Ask Questions Using the AI Retrieval API**

```mdx
POST /search/qna
```


**Request Body:**

```json
{
  "question": "What did the document say about pricing?",
  "session_id": "user-session-123",
  "tenant_id": "your_tenant_id",
  "context_list": ["optional_specific_file_id"],
  "ai_generation": true,
  "highlight_chunks": true,
  "tenant_metadata": {"source_title": "contract.pdf"},
  "document_metadata": {"source_title": "contract.pdf"}
}
```


**Example (cURL):**

```mdx
curl -X POST 'https://api.usecortex.ai/search/qna' \
  -H "Authorization: Bearer <your_api_key>" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Summarize the contract terms",
    "session_id": "user-123-session",
    "tenant_id": "your_tenant_id",
    "tenant_metadata": {"source_title": "contract.pdf"},
    "document_metadata": {"source_title": "contract.pdf"}
  }'
```


### **Step 4: Display the Answer in Your App**

You'll get a JSON response like:

```json
{
  "answer": "The contract specifies a 12-month term with a 30-day opt-out period...",
  "sources": [...],
  "chunks": [...]
}
```


Render the answer in your UI and include clickable citations if desired. Citations can reference:

- **Source filename** (e.g., `contract.pdf`)
- **Page number**
- **Snippet preview**

If available, use the `bounding_box` to enable clickable highlights or coordinate-based jumping in PDFs.

You can use the `tenant_metadata` and `document_metadata` parameters to restrict the context to only sources matching specific criteria:

- **`tenant_metadata`**: Filter by organizational attributes (department, compliance framework) that apply to all documents in your tenant
- **`document_metadata`**: Filter by document-specific attributes (title, author, document type) that vary per document

For example, `{ "source_title": "contract.pdf" }` will only use sources with that title for answering the question. You can combine both metadata types for precise filtering: `{ "department": "Legal", "document_type": "contract" }` to find all legal contracts.

### **Step 5: Iterate (Optional)**

Fine-tune the user experience with:

- `AI response (true or false)`: Lets you decide if you only want the retrieved context or the AI generated response to user queries using retrieved context
- `search_alpha (0-1)`: Prioritize keyword vs. semantic match. An alpha of "1" means semantic match. An Alpha of "0" means exact keyword match
- `recency_bias (0-1)`: Control how much you want to favour newly added knowledge. 1 you strongly favour recently added knowledge. 0 means freshness of knowledge doesn't matter.
- `highlight_chunks`: Get the actual context/chunks that can be used for generating answers for RAG or Agentic purposes
- `stream`: for real-time, streaming answers

### ðŸ§© Optional Extensions

- **Delete sources**: `POST /delete/delete-sources` to remove documents
- **List sources**: `POST /list/list-sources` to display all uploaded documents
- **Recall**: Use [Smart Recall](/api-reference/endpoint/smart) or [Keyword](/api-reference/endpoint/keyword) for semantic or keyword search